{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccdf4108-8924-412f-8dbf-acc638304637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "x_train:  (48000, 28, 28)\n",
      "y_train:  (48000,)\n",
      "x_val  :  (12000, 28, 28)\n",
      "y_val  :  (12000,)\n",
      "x_test :  (10000, 28, 28)\n",
      "y_test :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the MNIST dataset from TensorFlow's keras datasets module\n",
    "(x_train_loaded, y_train_loaded), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Create validation data (20%) from the training data (80%)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_loaded, y_train_loaded, test_size=0.2)\n",
    "\n",
    "# Print the size of datasets\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_val  : \", x_val.shape)\n",
    "print(\"y_val  : \", y_val.shape)\n",
    "print(\"x_test : \", x_test.shape)\n",
    "print(\"y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9be651-1958-4d69-934d-e811e34b8905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create 10\" by 10\" figures\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Using NumPy for efficient indexing\n",
    "x_train_np = np.array(x_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "for i in range(10):\n",
    "    # Get the indices of the labels that match 'i'\n",
    "    indices = np.where(y_train_np == i)[0]\n",
    "\n",
    "    # Pick the first image from those indices\n",
    "    img = x_train_np[indices[0]]\n",
    "\n",
    "    # Split the screen into 5 rows and 2 columns\n",
    "    plt.subplot(5, 2, i + 1)\n",
    "\n",
    "    # Use the count of indices as the title\n",
    "    plt.title(f\"len = {len(indices)}: {100*len(indices)/len(y_train_np):.2f}%\")\n",
    "\n",
    "    # Turn off axis\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80a03856-79f0-4214-ad43-03530ebaaa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of preprocessed training data (x_train): (48000, 28, 28, 1)\n",
      "Shape of preprocessed validation data (x_val): (12000, 28, 28, 1)\n",
      "Shape of preprocessed testing data (x_test): (10000, 28, 28, 1)\n",
      "Maximum pixel value in preprocessed training data: 1.0\n",
      "Maximum pixel value in preprocessed validation data: 1.0\n",
      "Maximum pixel value in preprocessed testing data: 1.0\n",
      "Shape of one-hot encoded training labels (y_train): (48000, 10)\n",
      "Shape of one-hot encoded validation labels (y_val): (12000, 10)\n",
      "Shape of one-hot encoded testing labels (y_test): (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(data, label=False):\n",
    "    # Ensure the data type conversion to 'float32'\n",
    "    data = data.astype('float32')\n",
    "\n",
    "    if label:\n",
    "        # Convert the label into a one-hot vector\n",
    "        return tf.keras.utils.to_categorical(data)\n",
    "    else:\n",
    "        # Normalize the data from 0 ~ 255 to 0 ~ 1\n",
    "        data /= 255\n",
    "\n",
    "        # Data augmentation can be integrated here if desired\n",
    "\n",
    "        # Prepare input for Keras by reshaping the data\n",
    "        # from (sample, width, height) to (sample, width, height, channel)\n",
    "        return data.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Preprocess data\n",
    "x_train = preprocess(x_train)\n",
    "x_val= preprocess(x_val)\n",
    "x_test = preprocess(x_test)\n",
    "\n",
    "# Preprocess labels\n",
    "y_train = preprocess(y_train, label=True)\n",
    "y_val = preprocess(y_val, label=True)\n",
    "y_test = preprocess(y_test, label=True)\n",
    "\n",
    "# Check data shape\n",
    "print(\"Shape of preprocessed training data (x_train):\", x_train.shape)\n",
    "print(\"Shape of preprocessed validation data (x_val):\", x_val.shape)\n",
    "print(\"Shape of preprocessed testing data (x_test):\", x_test.shape)\n",
    "\n",
    "# Check normalization\n",
    "print(\"Maximum pixel value in preprocessed training data:\", x_train.max())\n",
    "print(\"Maximum pixel value in preprocessed validation data:\", x_val.max())\n",
    "print(\"Maximum pixel value in preprocessed testing data:\", x_test.max())\n",
    "\n",
    "# Check one-hot vector\n",
    "print(\"Shape of one-hot encoded training labels (y_train):\", y_train.shape)\n",
    "print(\"Shape of one-hot encoded validation labels (y_val):\", y_val.shape)\n",
    "print(\"Shape of one-hot encoded testing labels (y_test):\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18152bac-4ec7-4d69-a6b8-f7e6425ea6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/miniconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.66.2-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow)\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/miniconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow)\n",
      "  Downloading rich-13.9.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow)\n",
      "  Downloading optree-0.12.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/miniconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl (236.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m236.3/236.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.2-cp312-cp312-macosx_10_9_universal2.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp312-cp312-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl (405 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading rich-13.9.1-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.2 h5py-3.12.1 keras-3.5.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-1.26.4 opt-einsum-3.4.0 optree-0.12.1 protobuf-4.25.5 rich-13.9.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 termcolor-2.4.0 werkzeug-3.0.4 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8c01e0-8e21-42f4-8d1d-37b2e398261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (48000, 28, 28)\n",
      "y_train:  (48000,)\n",
      "x_val  :  (12000, 28, 28)\n",
      "y_val  :  (12000,)\n",
      "x_test :  (10000, 28, 28)\n",
      "y_test :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the MNIST dataset from TensorFlow's keras datasets module\n",
    "(x_train_loaded, y_train_loaded), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Create validation data (20%) from the training data (80%)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_loaded, y_train_loaded, test_size=0.2)\n",
    "\n",
    "# Print the size of datasets\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_val  : \", x_val.shape)\n",
    "print(\"y_val  : \", y_val.shape)\n",
    "print(\"x_test : \", x_test.shape)\n",
    "print(\"y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d44c4df-d0ff-4ca1-98f5-6ef63cd881d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create our modern CNN model\n",
    "def create_sequential_model():\n",
    "    # Initialize a sequential model\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # ----- First Convolutional Block -----\n",
    "    # Add a 2D convolution layer with 32 filters, a 3x3 kernel, and padding to keep the spatial dimensions the same.\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv1', input_shape=(28, 28 , 1)))\n",
    "    # Normalize the activations of the previous layer. This can improve the convergence speed and model's overall performance.\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    # Use the ReLU activation function\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    # Pool the spatial dimensions by taking the maximum value in a 2x2 region.\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), name='pool1'))\n",
    "    # Randomly set a quarter of the input units to 0 to prevent overfitting.\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "    # ----- Second Convolutional Block -----\n",
    "    # Add another convolution layer, this time with 64 filters.\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', name='conv2'))\n",
    "    # Add batch normalization again\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    # Use the ReLU activation function\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    # Apply max pooling again to reduce spatial dimensions\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), name='pool2'))\n",
    "    # Apply dropout again to prevent overfitting\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "    # ----- Third Convolutional Block -----\n",
    "    # A third convolution layer, still with 64 filters.\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', name='conv3'))\n",
    "    # Add batch normalization\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    # Use the ReLU activation function\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "    # ----- Flattening and Dense layers -----\n",
    "    # Flatten the tensor output from the last convolutional layer\n",
    "    model.add(tf.keras.layers.Flatten(name='flatten'))\n",
    "    # Add a dense (fully connected) layer with 64 units\n",
    "    model.add(tf.keras.layers.Dense(64, name='dense4'))\n",
    "    # Add batch normalization\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    # Use the ReLU activation function\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    # Apply dropout before the final classification layer to prevent overfitting\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    # Add a dense layer for classification. Since MNIST has 10 classes, we use 10 units with softmax activation.\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax', name='dense5'))\n",
    "\n",
    "    # Return the constructed model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc00033-aa04-45b7-934c-a37ac446ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create our modern CNN model\n",
    "def create_sequential_model():\n",
    "    # Initialize a sequential model\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # ----- First Convolutional Block -----\n",
    "    # Add a 2D convolution layer with 32 filters, a 3x3 kernel, and padding to keep the spatial dimensions the same.\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv1', input_shape=(28, 28 , 1)))\n",
    "    # Normalize the activations of the previous layer. This can improve the convergence speed and model's overall performance.\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    # Use the ReLU activation function\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    # Pool the spatial dimensions by taking the maximum value in a 2x2 region.\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), name='pool1'))\n",
    "    # Randomly set a quarter of the input units to 0 to prevent overfitting.\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "    # ----- Second Convolutional Block -----\n",
    "    # Add another convolution layer, this time with 64 filters.\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', name='conv2'))\n",
    "    # Add batch normalization again\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    # Use the ReLU activation function\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    # Apply max pooling again to reduce spatial dimensions\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), name='pool2'))\n",
    "    # Apply dropout again to prevent overfitting\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "    # ----- Third Convolutional Block -----\n",
    "    # A third convolution layer, still with 64 filters.\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', name='conv3'))\n",
    "    # Add batch normalization\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    # Use the ReLU activation function\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "    # ----- Flattening and Dense layers -----\n",
    "    # Flatten the tensor output from the last convolutional layer\n",
    "    model.add(tf.keras.layers.Flatten(name='flatten'))\n",
    "    # Add a dense (fully connected) layer with 64 units\n",
    "    model.add(tf.keras.layers.Dense(64, name='dense4'))\n",
    "    # Add batch normalization\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    # Use the ReLU activation function\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    # Apply dropout before the final classification layer to prevent overfitting\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    # Add a dense layer for classification. Since MNIST has 10 classes, we use 10 units with softmax activation.\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax', name='dense5'))\n",
    "\n",
    "    # Return the constructed model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382e2f62-0f37-4580-92d4-581821a5c572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
       "\n",
       " batch_normalization_4            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \n",
       "\n",
       " batch_normalization_5            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \n",
       "\n",
       " batch_normalization_6            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">200,768</span> \n",
       "\n",
       " batch_normalization_7            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv1 (\u001b[38;5;33mConv2D\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m320\u001b[0m \n",
       "\n",
       " batch_normalization_4            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m128\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " activation_4 (\u001b[38;5;33mActivation\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_3 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2 (\u001b[38;5;33mConv2D\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m18,496\u001b[0m \n",
       "\n",
       " batch_normalization_5            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " activation_5 (\u001b[38;5;33mActivation\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_4 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv3 (\u001b[38;5;33mConv2D\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               \u001b[38;5;34m36,928\u001b[0m \n",
       "\n",
       " batch_normalization_6            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " activation_6 (\u001b[38;5;33mActivation\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense4 (\u001b[38;5;33mDense\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m200,768\u001b[0m \n",
       "\n",
       " batch_normalization_7            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                        \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " activation_7 (\u001b[38;5;33mActivation\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_5 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense5 (\u001b[38;5;33mDense\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                        \u001b[38;5;34m650\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">258,058</span> (1008.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m258,058\u001b[0m (1008.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">257,610</span> (1006.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m257,610\u001b[0m (1006.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the CNN model\n",
    "model = create_sequential_model()\n",
    "\n",
    "# Display a tabular view of the model's layers, output shapes, and the number of parameters.\n",
    "model.summary()\n",
    "\n",
    "# Compile the model, specifying the loss function, optimizer, and metric to monitor\n",
    "model.compile(\n",
    "    # Categorical crossentropy is a common loss function used for categorical classification tasks.\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "\n",
    "    # RMSprop optimizer adjusts the learning rate throughout training.\n",
    "    optimizer=tf.keras.optimizers.RMSprop(),\n",
    "\n",
    "    # Metric to monitor during training and testing.\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe6d984c-3b5c-4eed-9006-39417586c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "log_dir = '.'\n",
    "ckpt_name = 'weights-{epoch:02d}-{loss:.2f}-{categorical_accuracy:.2f}-{val_loss:.2f}-{val_categorical_accuracy:.2f}.weights.h5'\n",
    "\n",
    "cbs = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "    tf.keras.callbacks.ModelCheckpoint(os.path.join(log_dir, ckpt_name),\n",
    "                        monitor='val_categorical_accuracy',\n",
    "                        verbose=0,\n",
    "                        save_best_only=False,\n",
    "                        save_weights_only=True,  # You're only saving the weights\n",
    "                        mode='auto',\n",
    "                        save_freq='epoch')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c126208a-228a-4327-a102-b5bd4a27e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14ef159c-4427-4dd9-9267-4999389ef1c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape (48000, 28, 28, 1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(x_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)    \u001b[38;5;66;03m# Shape becomes (10000, 28, 28, 1)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Continue with data generation\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m train_data_gen \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow(x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     11\u001b[0m     train_data_gen,\n\u001b[1;32m     12\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x_train) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:1103\u001b[0m, in \u001b[0;36mImageDataGenerator.flow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow\u001b[39m(\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1091\u001b[0m     x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1102\u001b[0m ):\n\u001b[0;32m-> 1103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NumpyArrayIterator(\n\u001b[1;32m   1104\u001b[0m         x,\n\u001b[1;32m   1105\u001b[0m         y,\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1107\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1108\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m   1109\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1110\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m   1111\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[1;32m   1112\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[1;32m   1113\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[1;32m   1114\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[1;32m   1115\u001b[0m         ignore_class_split\u001b[38;5;241m=\u001b[39mignore_class_split,\n\u001b[1;32m   1116\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[1;32m   1117\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:612\u001b[0m, in \u001b[0;36mNumpyArrayIterator.__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_misc \u001b[38;5;241m=\u001b[39m x_misc\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m--> 612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data in `NumpyArrayIterator` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have rank 4. You passed an array \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m     )\n\u001b[1;32m    617\u001b[0m channels_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[channels_axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m}:\n",
      "\u001b[0;31mValueError\u001b[0m: Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape (48000, 28, 28, 1, 1)"
     ]
    }
   ],
   "source": [
    "# Reshape the data to add the channel dimension\n",
    "x_train = np.expand_dims(x_train, axis=-1)  # Shape becomes (48000, 28, 28, 1)\n",
    "x_val = np.expand_dims(x_val, axis=-1)      # Shape becomes (12000, 28, 28, 1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)    # Shape becomes (10000, 28, 28, 1)\n",
    "\n",
    "# Continue with data generation\n",
    "train_data_gen = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=len(x_train) // batch_size,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=epochs,\n",
    "    callbacks=cbs,\n",
    "    verbose=verbose\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9015489f-1194-457c-80dc-3083f06cd4b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(acc)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "plt.plot(epochs, acc, 'b', label='Training categorical accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Val categorical accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "588f7471-aa03-4082-b7f8-f0d03cc0293e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(loss)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss)+1 )\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb5f03-e34b-40e8-ad9c-f262753c0266",
   "metadata": {},
   "source": [
    "##Notes:\n",
    "\n",
    "###What are the shapes (sizes) of x_train, x_val, and x_test?\n",
    "x_train = (48000, 28, 28) <br />\n",
    "x_val = (12000, 28, 28) <br />\n",
    "x_test = (10000, 28, 28)\n",
    "\n",
    "###What do the shapes (sizes) of x_train, x_val, and x_test represent?\n",
    "\n",
    "Training (48000 28x28 images), validation (12000 28x28 images), and testing data (10000 28x28 images).\n",
    "\n",
    "###What are y_train, x_val, and y_test for?\n",
    "Organising the data based on use (training, validation, and testing data). \n",
    "\n",
    "###How would you modify the code if you wanted to use a different dataset provided by keras.datasets, such as fashion_mnist?\n",
    "(x_train_loaded, y_train_loaded), (x_test, y_test) = tf.keras.datasets.**fashion_mnist**.load_data()\n",
    "\n",
    "###If the MNIST images are grayscale, what would you expect the range of pixel values to be?\n",
    "0-255, one plane. \n",
    "\n",
    "###Explain the significance of the 80-20 split when creating a validation set. Are there scenarios where you might choose a different split?\n",
    "It is common to use most of the data for training and a smaller amount for validation. Within a larger set, a 90-10 split may be sufficient and within a smaller set, a 70-30 split may be sufficient. \n",
    "\n",
    "###What kind of data does the MNIST dataset contain, and why is it commonly used in machine learning and deep learning courses?\n",
    "The MNIST dataset contains images of handwriting, specifically of numbers from 0 to 9. \n",
    "\n",
    "--\n",
    "\n",
    "###How do we plot the last image instead of the first image?\n",
    "```python\n",
    "img = x_train_np[indices[-1]]\n",
    "```\n",
    "###Which handwriting digit image do we have the most in the dataset?\n",
    "1 (11.24%)\n",
    "###Which handwriting digit image do we have the least in the dataset?\n",
    "5 (8.90%)\n",
    "###How can we modify the code to display three images for each digit side by side?\n",
    "Change **2** to **3**: <br />\n",
    "```python\n",
    "plt.subplot(5, 3, i + 1)\n",
    " ```\n",
    "###How would you adjust the code to display the images in a 10x1 grid (10 rows and 1 column) instead of a 5x2 grid?\n",
    "```python\n",
    "plt.subplot(10, 1, i + 1)\n",
    "```\n",
    "Though the spacing for the information displayed needs to be reformatted to not overlap. \n",
    " \n",
    "###Why do we use cmap='gray' when displaying the images? What happens if you remove it?\n",
    "```python\n",
    "cmap='gray'\n",
    "``` \n",
    "Allows us to see an images for each of the numbers. Removing causes the image to not render.\n",
    "###How can we modify the code to display the average image of each digit (i.e., the mean pixel value for each position)?\n",
    "I knew that I needed to find the average values of x and y for each number but I was unsure how to do it. From Chat GPT;\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    indices = np.where(y_train_np == i)[0]\n",
    "    mean_img = np.mean(x_train_np[indices], axis=0)  # Compute the mean image\n",
    "    plt.subplot(5, 2, i + 1)\n",
    "    plt.title(f\"Digit {i}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(mean_img, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "###Why might it be essential to know which handwriting digit images are most or least common in the dataset?\n",
    "\n",
    "A model may have a bias towards most common images in a dataset. Knowing which handwriting digital images are least common can help inform of decisions made when selecting data to analyse and adjusting for any problems with the model. \n",
    "\n",
    "--\n",
    "###What is the value of x_train.max(), and why are we printing it?\n",
    "The value of x_train.max() is 1.0, it shows that the values have been normalised. \n",
    "\n",
    "###What would the x_train.min() value be after preprocessing? Explain why.\n",
    "?\n",
    "\n",
    "###How is the shape of y_train, y_val, and y_test different from before the preprocessing step?\n",
    "?\n",
    "\n",
    "###How is the One-Hot vector representing the label for each data?\n",
    "Converts an interger into a vector with a length of 10. \n",
    "\n",
    "###How is the normalization achieved for the image data?\n",
    "Dividng the grey scale values by 255. \n",
    "\n",
    "###Why do we need to reshape the image data for CNNs and not just use the flattened version like in MLPs?\n",
    "The input data for CNN needs to retain its original dimensions, unlike MLP which simply adds all the values of the pixels together. \n",
    "\n",
    "###Why is applying the same preprocessing steps to training and testing datasets important?\n",
    "It helps to ensure that the model is able to learn properly by keeping different variables consistent. Much like a science experiment with controlled variables. \n",
    "\n",
    "###Given that the MNIST dataset consists of ten digits (0-9), what is the expected size of the one-hot encoded vector for the labels? Why?\n",
    "Size of 10. The length of the vector is equal to the number of digits. \n",
    "\n",
    "--\n",
    "###What can you infer about the output map as the CNN layers progress towards the output?\n",
    "As the layers progress, the model starts by detecting simpler patterns (like edges) to identifying hmore complex patterns (like shapes or digit components).\n",
    "\n",
    "###Do the images from the CNN layers seem to capture the higher-order feature? If so, what?\n",
    "Later layers may start to capture more complex patterns like specific brush strokes or 'styles'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6090a2-4e40-473e-9354-1bd19d648cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
